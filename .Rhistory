control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
} else {
hier_time <- stan(stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
}
}
hier_time <- stan(stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
source('~/DEEPEst/R/stanmodels.R')
hier_time <- stan(stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
detach("package:DEEPEst", unload = TRUE)
library(DEEPEst)
DEEPEst::Stan_Time_Estimation(project_name = 'test', num_question_Est = 16, num_question = 16, type_theta = 'Hier', directory = '/Users/ap/Desktop')
# names of stan models
stanmodels <- c("Stan_Risk_Global", "Stan_Risk_Hier", "Stan_Risk_Individual", "Stan_Time_Global", "Stan_Time_Hier", "Stan_Time_Individual")
getwd()
rm(stanmodels)
hier_time <- stan(stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
hier_time <- stan(DEEPEst::stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
remove.packages("DEEPEst")
devtools::install_github("ColumbiaCDS/DEEPEst")
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
rstan::stan
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise(clean=TRUE)
setwd("~/DEEPEst")
roxygen2::roxygenise(clean=TRUE)
source('~/DEEPEst/R/Stan_Time_Estimation.R')
library(roxygen2)
vignette("rd", package = "roxygen2")
roxygen2::roxygenise()
devtools::document()
pkgbuild::compile_dll()
devtools::document()
vignette("rd", package = "roxygen2")
roxygen2::roxygenise()
DEEPEst::Time_save_stantocsv(project_name = 'test',num_question_Est = 16, type_theta = 'Hier', path = path)
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
setwd("~/DEEPEst")
roxygen2::roxygenise()
roxygen2::roxygenise()
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
roxygen2::roxygenise()
roxygen2::roxygenise()
remove.packages("DEEPEst")
devtools::install_github("ColumbiaCDS/DEEPEst")
library(DEEPEst)
roxygen2::roxygenise()
path <-'/Users/ap/Desktop'
project_name <-'test'
num_question_Est
num_question_Est <- 16
type_theta <- 'Hier'
Time_dist_estimates(project_name, num_question_Est, type_theta, path)
Time_plot_cor(project_name, num_question_Est, type_theta, path, 'beta', 'theta')
Time_plot_cor(project_name, num_question_Est, type_theta, path, 'beta', 'delta')
Time_plot_cor(project_name, num_question_Est, type_theta, path, 'r', 'delta')
Time_save_stantocsv(project_name, num_question_Est, type_theta, path)
Time_data_prepare(project_name, path, num_question = 16)
Stan_Time_Estimation(project_name, num_question_Est, num_question = 16, type_theta, path)
num_question_Est
num_question
num_question <- 16
# Make sure the type of delta used is correct
stopifnot(type_theta %in% c('Global', 'Individual', 'Hier'))
gambles1 <- read.csv(paste0(path, '/', project_name, '_Time_options_chosen.csv')
, header = F, col.names = c("ssamount","ssdelay"))
gambles2 <- read.csv(paste0(path, '/', project_name, '_Time_options_notchosen.csv')
, header = F, col.names = c("llamount","lldelay"))
serials <- read.csv(paste0(path, '/', project_name, '_Time_serials.csv'), header = F)
subjectNumber <- nrow(serials)
all_Stan_data <- data.frame(SubjectID = NA, QuestionNum = NA, SS_Amount = gambles1$ssamount, SS_Delay = gambles1$ssdelay,
LL_Amount = gambles2$llamount, LL_Delay = gambles2$lldelay, Choice = 0)
all_Stan_data <- Time_index_Questions(all_Stan_data, subjectNumber, num_question)
# create data list for running Stan
Time_prepare_Stan(all_Stan_data, num_question_Est, subjectNumber)
# Set initial values to begin MCMC sampling based on empirical knowledge
chain <- list('beta' = rep(0.8, subjectNumber), 'r' = rep(0.002, subjectNumber),
'delta' = rep(exp(-365*0.002), subjectNumber), 'theta' = rep(0.5, subjectNumber),
'delta_phi' = rep(0, subjectNumber),
'mubeta' = 0.8, 'sigmabeta' = 0.2,
'mudelta_phi' = 0, 'sigmadelta_phi' = 0.2,
'mutheta' = -1, 'sigmatheta' = 1)
initial_chains <- list(chain, chain, chain)
# run stan model with indiviual or global or hierarchical scaling response noise parameter
if (type_theta == 'Global') {
hier_time <- stan(stanmodels$Stan_Time_Global,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
} else {
if (type_theta == 'Individual'){
hier_time <- stan(stanmodels$Stan_Time_Individual,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
} else {
hier_time <- stan(stanmodels$Stan_Time_Hier,
data = moddat,
chains = chains,
iter = iter,
init = initial_chains,
thin = thin,
control = list(adapt_delta = adapt_delta,
max_treedepth = max_treedepth,
stepsize = stepsize))
}
}
Risk_dist_estimates(project_name, num_question_Est = 8, type_theta, path)
num_question_Est <- 8
# Make sure the type of delta used is correct
stopifnot(type_theta %in% c('Global', 'Individual', 'Hier'))
load(paste0(path, '/Stan_Risk_', project_name, '_Est', type_theta, num_question_Est,
'questions.RData'))
estimates <- rstan::extract(hier_risk)
subtitle <- paste0(project_name, ' Risk Estimated by ',
type_theta, ' theta with ', num_question_Est, ' questions')
alphas <- colMeans(estimates$alpha)
sigmas <- colMeans(estimates$sigma)
lambdas <- colMeans(estimates$lambda)
dist_alphas <- ggplot() +
geom_histogram(mapping = aes(x = alphas), bins = 30) +
labs(x = 'Individual alphas') +
geom_vline(xintercept = mean(alphas), color = 'red') +
annotate("text", x = mean(alphas), y = 40,
label = paste0("Mean: ", round(mean(alphas),4)), col="red") +
geom_vline(xintercept = median(alphas), color = 'green') +
annotate("text", x = median(alphas), y = 60,
label = paste0("Median: ", round(median(alphas),4)), col="green") +
labs(title = subtitle) +
xlim(c(mean(alphas) - 2*sd(alphas), mean(alphas) + 2*sd(alphas)))
dist_sigmas <- ggplot() +
geom_histogram(mapping = aes(x = sigmas), bins = 40) +
labs(x = 'Individual sigmas') +
geom_vline(xintercept = mean(sigmas), color = 'red') +
annotate("text", x = mean(sigmas), y = 40,
label = paste0("Mean: ", round(mean(sigmas),4)), col="red") +
geom_vline(xintercept = median(sigmas), color = 'green') +
annotate("text", x = median(sigmas), y = 60,
label = paste0("Median: ", round(median(sigmas),4)), col="green") +
labs(title = subtitle) +
xlim(c(mean(sigmas) - 2*sd(sigmas), mean(sigmas) + 2*sd(sigmas)))
dist_lambdas <- ggplot() +
geom_histogram(mapping = aes(x = lambdas), bins = 30) +
labs(x = 'Individual lambdas') +
geom_vline(xintercept = mean(lambdas), color = 'red') +
annotate("text", x = mean(lambdas), y = 40,
label = paste0("Mean: ", round(mean(lambdas),4)), col="red") +
geom_vline(xintercept = median(lambdas), color = 'green') +
annotate("text", x = median(lambdas), y = 60,
label = paste0("Median: ", round(median(lambdas),4)), col="green") +
labs(title = subtitle) +
xlim(c(mean(lambdas) - 2*sd(lambdas), mean(lambdas) + 2*sd(lambdas)))
grid.arrange(dist_alphas, dist_sigmas, dist_lambdas, cols=1)
dist_lambdas
gridExtra::grid.arrange(dist_alphas, dist_sigmas, dist_lambdas, cols=1)
grid.arrange(dist_alphas, dist_sigmas, dist_lambdas, ncol = 1)
Time_dist_estimates(project_name, num_question_Est = 16, type_theta, path)
Risk_plot_cor(project_name, num_question_Est = 8, type_theta, path, 'alpha', 'lambda')
Risk_plot_cor(project_name, num_question_Est = 8, type_theta, path, 'alpha', 'simga')
Risk_plot_cor(project_name, num_question_Est = 8, type_theta, path, 'alpha', 'simga')
Risk_plot_cor(project_name, num_question_Est = 8, type_theta, path, 'alpha', 'sigma')
Risk_save_stantocsv(project_name, num_question_Est = 8, type_theta, path)
Risk_save_stantocsv(project_name, num_question_Est = 8, type_theta, path)
Stan_Risk_Estimation(project_name, num_question_Est = 8, type_theta, path)
type_theta
Stan_Risk_Estimation(project_name = project_name, num_question_Est = 8, type_theta = type_theta, path = path)
Stan_Risk_Estimation(project_name = project_name, num_question_Est = 8, num_question = 8, type_theta = type_theta, path = path)
# Make sure the type of delta used is correct
stopifnot(type_theta %in% c('Global', 'Individual', 'Hier'))
gambles1 <- read.csv(paste0(path, '/', project_name, '_Risk_options_chosen.csv')
, header = F, col.names = c("x1","p1", "y1", "q1"))
gambles2 <- read.csv(paste0(path, '/', project_name, '_Risk_options_notchosen.csv')
, header = F, col.names = c("x2","p2", "y2", "q2"))
serials <- read.csv(paste0(path, '/', project_name, '_Risk_serials.csv'), header = F)
subjectNumber <- nrow(serials)
Stan_Risk_Estimation(project_name = project_name, num_question_Est = 8, num_question = 20, type_theta = type_theta, path = path)
source('~/DEEPEst/R/Stan_Time_Estimation.R')
source('~/DEEPEst/R/Stan_Time_Estimation.R')
remove.packages("DEEPEst")
devtools::install_github("ColumbiaCDS/DEEPEst")
Stan_Time_Estimation(project_name, num_question_Est = 16, num_question = 16, type_theta = type_theta, path = path)
roxygen2::roxygenise()
remove.packages("DEEPEst")
devtools::install_github("ColumbiaCDS/DEEPEst")
Stan_Time_Estimation(project_name, num_question_Est = 16, num_question = 16, type_theta = type_theta, path = path)
Stan_Risk_Estimation(project_name, num_question_Est = 8, num_question = 8, type_theta = type_theta, path = path)
Stan_Risk_Estimation(project_name, num_question_Est = 8, num_question = 20, type_theta = type_theta, path = path)
source('~/Desktop/DEEP Final/Functions_Risk.r')
num_question_Est = 8
num_question = 10
SimID <- 11
type_theta <- 'Hier'
how_generated <- 'IND'
path <- '/Users/ap/Desktop/DEEP Final'
Stan_Risk_Estimation(SimID = SimID, num_question_Est = num_question_Est, num_question = num_question, path = path, how_generated = how_generated, type_theta = type_theta)
library(cli)
source('~/Desktop/DEEP Final/Functions_Risk.r')
source('~/Desktop/DEEP Final/Functions_Risk.r')
source('~/Desktop/DEEP Final/Functions_Risk.r')
source('~/Desktop/DEEP Final/Functions_Time.r')
Risk_save_stantocsv(SimID = SimID, num_question_Est = num_question_Est, type_thetatype_theta, how_generated = how_generated, path = path)
Risk_save_stantocsv(SimID = SimID, num_question_Est = num_question_Est, type_theta= type_theta, how_generated = how_generated, path = path)
source('~/Desktop/DEEP Final/Functions_Risk.r')
Risk_save_stantocsv(SimID = SimID, num_question_Est = num_question_Est, type_theta= type_theta, how_generated = how_generated, path = path)
Risk_stan_result(SimID = SimID, type_theta = type_theta, how_generated = how_generated, path = path, num_question_Est = num_question_Est)
source('~/Desktop/DEEP Final/Functions_Risk.r')
Risk_repeat_Estimation_thetatype(SimID = SimID, path = path, num_question = num_question, num_question_Est = num_question_Est, n_repeat = 2, how_generated = how_generated)
warnings()
Risk_plot_distributions(how_generated = how_generated, SimID = 11, n_repeat = 2, path = path, num_question_Est = 8)
warnings()
Risk_dist_estimates(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
Risk_plot_cor(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path, parameter1 = 'alpha', parameter2 = 'lambda')
source('~/Desktop/DEEP Final/Functions_Risk.r')
Risk_plot_cor(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path, parameter1 = 'alpha', parameter2 = 'lambda')
Risk_dist_estimates(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
Time_dist_estimates(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
source('~/Desktop/DEEP Final/Functions_Time.r')
Time_dist_estimates(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
Risk_dist_estimates(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
Risk_plot_cor(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path, parameter1 = 'alpha', parameter2 = 'lambda')
Risk_stan_result(SimID = SimID, num_question_Est = 8, type_theta = type_theta, how_generated = how_generated, path = path)
# Stan estimation script for Simulated Time Data
############## Customization Part begins #####################
path <- "/User/ap/Desktop/DEEP Final"       # Enter your full working directory path. In my example: path <- "./DEEP Qi"
SimID <- 11    # Enter the SimID for this simulation dataset you set in simulation
how_generated <- "IND"   # Enter either 'GLO' or 'IND' indicates which version of response noise parameter you set in this simulation
num_question <- 10 # How many questions asked for each subject in this simulation
num_question_Est <- 5  # How many questions are used for parameter estimation, less or equal to num_question
type_theta <- "Hier"   # Either 'Global', 'Individual' or 'Hier'. Which version of scaling response noise parameter setting
# do you want in this estimation
############## Customization Part ends #####################
source(paste0(path, '/Functions_Time.r'))
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()-1)
#####  Estimation Part begins #################################
# Stan Time Estimaiton
Stan_Time_Estimation(SimID = SimID,
num_question_Est = num_question_Est,
num_question = num_question,
type_theta = type_theta,
how_generated = how_generated,
path = path)
##### Save the estimates out from stanfit object into csv files
Time_save_stantocsv(SimID = SimID,
num_question_Est = num_question_Est,
type_theta = type_theta,
how_generated = how_generated,
path = path)
#### Calculate metrics in measuring recovery accuracy
Time_stan_result(SimID = SimID,
type_theta = type_theta,
how_generated = how_generated,
path = path,
num_question_Est = num_question_Est)
#####  Estimation Part begins #################################
# Stan Time Estimaiton
Stan_Time_Estimation(SimID = SimID,
num_question_Est = num_question_Est,
num_question = num_question,
type_theta = type_theta,
how_generated = how_generated,
path = path)
# Stan estimation script for Simulated Time Data
############## Customization Part begins #####################
path <- "/Users/ap/Desktop/DEEP Final"       # Enter your full working directory path. In my example: path <- "./DEEP Qi"
SimID <- 11    # Enter the SimID for this simulation dataset you set in simulation
how_generated <- "IND"   # Enter either 'GLO' or 'IND' indicates which version of response noise parameter you set in this simulation
num_question <- 10 # How many questions asked for each subject in this simulation
num_question_Est <- 5  # How many questions are used for parameter estimation, less or equal to num_question
type_theta <- "Hier"   # Either 'Global', 'Individual' or 'Hier'. Which version of scaling response noise parameter setting
# do you want in this estimation
############## Customization Part ends #####################
source(paste0(path, '/Functions_Time.r'))
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()-1)
#####  Estimation Part begins #################################
# Stan Time Estimaiton
Stan_Time_Estimation(SimID = SimID,
num_question_Est = num_question_Est,
num_question = num_question,
type_theta = type_theta,
how_generated = how_generated,
path = path)
##### Save the estimates out from stanfit object into csv files
Time_save_stantocsv(SimID = SimID,
num_question_Est = num_question_Est,
type_theta = type_theta,
how_generated = how_generated,
path = path)
#### Calculate metrics in measuring recovery accuracy
Time_stan_result(SimID = SimID,
type_theta = type_theta,
how_generated = how_generated,
path = path,
num_question_Est = num_question_Est)
# Stan estimation script for Simulated Risk Data
############## Customization Part begins #####################
path <- "/Users/ap/Desktop/DEEP Final"       # Enter your full working directory path. In my example: path <- "./DEEP Qi"
SimID <- 11    # Enter the SimID for this simulation dataset you set in simulation
how_generated <- "IND"   # Enter either 'GLO' or 'IND' indicates which version of response noise parameter you set in this simulation
num_question <- 10 # How many questions asked for each subject in this simulation
num_question_Est <- 5  # How many questions are used for parameter estimation, less or equal to num_question
type_theta <- "Hier"   # Either 'Global', 'Individual' or 'Hier'. Which version of scaling response noise parameter setting
# do you want in this estimation
############## Customization Part ends #####################
source(paste0(path, '/Functions_Risk.r'))
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()-1)
#####  Estimation Part begins #################################
# Stan Risk Estimaiton
Stan_Risk_Estimation(SimID = SimID,
num_question_Est = num_question_Est,
num_question = num_question,
type_theta = type_theta,
how_generated = how_generated,
path = path)
##### Save the estimates out from stanfit object into csv files
Risk_save_stantocsv(SimID = SimID,
num_question_Est = num_question_Est,
type_theta = type_theta,
how_generated = how_generated,
path = path)
#### Calculate metrics in measuring recovery accuracy
Risk_stan_result(SimID = SimID,
type_theta = type_theta,
how_generated = how_generated,
path = path,
num_question_Est = num_question_Est)
remove.packages("DEEPEst")
devtools::install_github("ColumbiaCDS/DEEPEst")
1705129
1534617+170512
700*8*256
700*256
17.5+26+7
50.5/5*7
50.5*200
10100+3000+50*15
690+7119
4/11
(1/0.8+1/0.7+1/0.8)/11
source('~/DEEPEst/R/Time_data_prepare.R')
source('~/DEEPEst/R/Time_data_prepare.R')
if (!require("remotes")) {
install.packages("remotes")
}
remotes::install_github("stan-dev/rstantools")
library(rstantools)
path = '/Users/ap/DEEPEst_0624'
install.packages("StanHeaders")
remove.packages("StanHeaders")
install.packages("StanHeaders")
path
rstantools::rstan_create_package(path = path, stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
path
rstantools::rstan_create_package(path = "/Users/ap/DEEPEst_0624", stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
rstantools::rstan_create_package(path = "DEEPEst_0624", stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
rstantools::rstan_create_package(path = "DEEPEst_0624", stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
rstantools::rstan_create_package(path = "DEEPEst0624", stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
rstantools::rstan_create_package(path = "DEEPEst0624", stan_files = c('/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Time_Hier.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Global.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Individual.stan', '/Users/ap/Documents/Columbia/RA CDS/DEEP/DEEP New Pages/3.4.2. Run Stan Estimation on Simulated Data/Stan_Risk_Hier.stan'))
pkgbuild::compile_dll()
setwd("~/DEEPEst0624")
pkgbuild::compile_dll()
devtools::document()
roxygen2::roxygenize()
#' Read, Clean and Denoise Risk Survey Data
#' @description Read and denoise the original suvery output data. Only complete rows would be reserved. In addition, this function automatically drops those "unengaged" responses (noisy ones with only random choices, not involving utility consideration).
#' Once you obtain the original output csv file from DEEP survey under directory \code{path}, rename it to be "DEEP_\{\code{model}\}_surveydata_\{\code{project_name}\}.csv", where "\code{model}" is either "Time" or "Risk".
#' @param project_name The name of this study.
#' @param path Full path for working directory.
#' @param num_question How many questions are asked for each subject in this suvery.
#' @param each_seconds How many seconds spent on each question on average so that the observation would be considered as a reasonable response.
#' @param clean_time Logical value. Default is \code{TRUE} means you want to denoise the original data by dropping all responses which are completed within \code{num_question} times \code{each_seconds} seconds.
#' @param clean_side Logical value. Default is \code{TRUE} means you want to denoise the original data by dropping all responses which only contain one-side options, namely, only left or right options chosen.
#'
#' @import dplyr
#'
#' @return Three csv files will be saved under directory indicated by \code{path} and used in estimation function \code{\link{Stan_Risk_Estimation}}:
#' \itemize{
#'   \item "\{\code{project_name}\}_Risk_options_chosen.csv" contains amounts of rewards (first column) and delayed days (second column) of all chosen options. The number of rows is \code{num_question} times \code{num_subjects}, where \code{num_subjects} is the number of subjects in this survey after denoising.
#'   \item "\{\code{project_name}\}_Risk_options_notchosen.csv" is same as the above one except this contains data of unchosen options among all questions.
#'   \item "\{\code{project_name}\}_Risk_serials.csv" contains serial number for each subject as identification.
#' }
#' @export
#'
#' @examples
#' Risk_data_prepare(project_name = 'test', path = '/Users/ap/Desktop', num_question = 12)
Risk_data_prepare <- function(project_name,
path,
num_question,
clean_time = T,
clean_side = T,
each_seconds = 2
){
original <- read.csv(paste0(path, '/DEEP_Risk_surveydata_', project_name, '.csv'), as.is = T, header = T)
# Keep only complete rows
original <- original[complete.cases(original),]
rownames(original) <- seq(nrow(original))
if (clean_time == T){
# Drop all responses with random choices defined by using time less than each_seconds seconds on average
# This argument controls how we regard responses as noisy responses completed just randomly by subjects.
#During data cleaning, we will first drop responses which are finished within (each_seconds * num_questions) seconds in total.
used_time <- original %>% group_by(participant) %>% summarise(sum = sum(timesincepresentation))
original <- original %>% filter(participant %in% used_time$participant[used_time$sum > num_question * each_seconds])
rownames(original) <- seq(nrow(original))
}
if (clean_side == T){
# It also drops all responses which contain only one-side options (only left or right chose options).
# Min seconds spent on each question on average so that the responses would be considered as a normal response,
# otherwise, they will be considered as noisy ones and dropped.
all_oneside <- original %>% group_by(participant) %>% summarise(one_side = all(chosenside == 1) | all(chosenside == 0))
original <- original %>% filter(participant %in% all_oneside$participant[all_oneside$one_side == FALSE])
rownames(original) <- seq(nrow(original))
}
subjectNumber <- length(unique(original$participant))
# Attention, as default gambles1 will contain the actual options made by subjects
gambles1 <- matrix(c(original$chosenamount1, original$chosenprob1, original$chosenamount2, original$chosenprob2), ncol = 4)
gambles2 <- matrix(c(original$nonchosenamount1, original$nonchosenprob1, original$nonchosenamount2, original$nonchosenprob2), ncol = 4)
write.table(x = gambles1, paste0(path, '/', project_name, '_Risk_options_chosen.csv'), col.names = F, row.names = F, sep = ',')
write.table(x = gambles2, paste0(path, '/', project_name, '_Risk_options_notchosen.csv'), col.names = F, row.names = F, sep = ',')
write.table(unique(original$serial), paste0(path, '/', project_name, '_Risk_serials.csv'), row.names = F, col.names = F, sep = ',')
}
path <- '/Users/ap/Desktop'
Risk_data_prepare(project_name = 'test', path = path, num_question = 16, each_seconds = 2)
Risk_data_prepare(project_name = 'test', path = path, num_question = 16, each_seconds = 2)
